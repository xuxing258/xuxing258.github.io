import{_ as e,c as i,a as s,o as n}from"./app-oYpRxrJy.js";const a={};function t(o,l){return n(),i("div",null,[...l[0]||(l[0]=[s(`<h2 id="什么爬虫" tabindex="-1"><a class="header-anchor" href="#什么爬虫"><span>什么爬虫</span></a></h2><p>网络爬虫（Web Crawler），也叫网络蜘蛛（Web Spider）或网络机器人（Web Robot），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本</p><p>比如遇到这样的需求, 希望能够保存互联网上的一些重要的数据信息为己所用，示例:</p><ol><li>在浏览到一些优秀的图片时,总想保存起来留为日后做桌面上的壁纸</li><li>在浏览到一些重要的数据时(各行各业),希望保留下来日后为自己进行各种销售行为增光添彩</li><li>在浏览到一些奇奇怪怪的劲爆视频时,希望保存在硬盘里供日后慢慢品鉴</li><li>在浏览到一些十分优秀的歌声曲目时,希望保存下来供我们在烦闷的生活中增添一份精彩</li></ol><p>爬虫就是通过编写程序来爬取互联网上的优秀资源(图片,音频,视频,数据)等等</p><p><strong>爬虫可以自动化浏览网络中的信息</strong>: 当然浏览信息的时候需要按照我们制定的规则进行，这些规则我们称之为网络爬虫算法。而Python可以很方便地编写出爬虫程序，进行互联网信息的自动化检索并保存</p><h3 id="通用网络爬虫" tabindex="-1"><a class="header-anchor" href="#通用网络爬虫"><span><strong>通用网络爬虫</strong></span></a></h3><blockquote><p>常用搜索引擎: 功能强大,采集面广, 百度 360 谷歌等等</p></blockquote><p><strong>搜索引擎</strong>离不开爬虫，比如<strong>百度</strong>搜索引擎的爬虫叫作百度蜘蛛（Baiduspider）。百度蜘蛛每天会在海量的互联网抓取各种类型的网页，然后对这些网页进行分析和索引, 爬取优质信息并收录，当用户在百度搜索引擎上检索对应关键词时，百度将对关键词进行分析处理，从收录的网页中找出相关网页，按照一定的排名规则进行排序并将结果展现给用户</p><h3 id="聚焦网络爬虫" tabindex="-1"><a class="header-anchor" href="#聚焦网络爬虫"><span><strong>聚焦网络爬虫</strong></span></a></h3><blockquote><p>常用于爬虫岗位(主要应用): 明确要爬取的主题领域，如“财经新闻”、“二手车价格”、“招聘信息”、“房产楼盘”等。</p></blockquote><p>聚焦爬虫则是有针对性地抓取特定主题或领域的网页。例如，一个专注于新闻领域的聚焦爬虫，只会抓取与新闻相关的网页，而不会去抓取其他不相关的网页，如购物网站、游戏网站等</p><h3 id="增量式网络爬虫" tabindex="-1"><a class="header-anchor" href="#增量式网络爬虫"><span><strong>增量式网络爬虫</strong></span></a></h3><blockquote><p>聚焦爬虫的迭代(进阶): 区分新老数据 (采集更新后的内容), 设置多久时间之后重新采集一次</p></blockquote><ul><li><strong>聚焦爬虫</strong>解决了“爬什么”（目标范围）的问题。</li><li><strong>增量式爬虫</strong>解决了“何时爬、如何高效爬”（更新策略）的问题</li></ul><p>这种爬虫的特点是只抓取新出现的或发生变化的网页。它会记录每次抓取的时间和网页的状态，下次抓取时只获取自上次抓取以来更新的网页，这样可以节省大量的时间和资源，提高爬虫的效率, 比如(爬取更新后的内容:漫画, 视频等)</p><h3 id="robots协议" tabindex="-1"><a class="header-anchor" href="#robots协议"><span>robots协议</span></a></h3><p>Robots 协议（也称为爬虫协议、机器人协议等），其英文全称为 “Robots Exclusion Protocol”，是一种国际通行的道德规范，用于告知网络爬虫哪些页面可以抓取，哪些页面不能抓取，以此来保护网站的隐私和安全，规范网络爬虫的行为</p><p><strong>局限性</strong>：需要注意的是，Robots 协议只是一种道德规范，而不是法律强制规定。也就是说，虽然大多数正规的网络爬虫会遵守这一协议，但仍有一些恶意爬虫可能会无视 Robots 协议，强行抓取被禁止访问的内容。</p><p>君子协定：指代的是口头上的协议，如果爬取了，可能会出现法律纠纷（商用）</p><p>小米: <a href="https://www.mi.com/robots.txt" target="_blank" rel="noopener noreferrer">https://www.mi.com/robots.txt</a></p><p>百度: <a href="https://www.baidu.com/robots.txt" target="_blank" rel="noopener noreferrer">https://www.baidu.com/robots.txt</a></p><p><img src="https://api2.mubu.com/v3/document_image/7637318_439a07fd-38fc-4c20-dcd5-6743ea427435.png" alt=""></p><ul><li><strong>User-agent</strong>：用来指定适用的网络爬虫名称。“User-agent: *” 表示该规则适用于所有网络爬虫；也可以指定特定的爬虫名称， <ul><li>如 “User-agent: Baiduspider”，则仅对百度搜索引擎的爬虫生效。</li><li><code>User-agent: Googlebot</code>：仅匹配谷歌的爬虫。</li></ul></li><li><strong>Disallow</strong>：用于指定不允许爬虫访问的页面或目录。例如，“Disallow: /admin/” 表示禁止所有爬虫访问网站的 /admin/ 目录及其下的所有页面； <ul><li>“Disallow: /page.html” 则表示禁止访问特定的 page.html 页面</li></ul></li><li><strong>Allow</strong>：与 Disallow 相反，用于指定允许爬虫访问的页面或目录（在部分情况下使用）。 <ul><li>如 “Allow: /public/” 表示允许爬虫访问网站的 /public/ 目录。</li></ul></li></ul><h3 id="法律和道德问题" tabindex="-1"><a class="header-anchor" href="#法律和道德问题"><span><strong>法律和道德问题</strong></span></a></h3><p>例如，不能抓取受版权保护的内容，不能违反网站的使用条款，不能过度抓取导致网站服务器负担过重等。许多网站会通过设置 robots.txt 文件来告知爬虫哪些页面可以抓取，哪些页面不可以抓取，爬虫应该遵守这些规定</p><h2 id="pip使用" tabindex="-1"><a class="header-anchor" href="#pip使用"><span>pip使用</span></a></h2><ul><li>pip -v 查看版本</li><li>pip config set global.index-url 设置下载源</li><li>pip install 下载</li><li>pip uninstall 卸载</li><li>pip list 显示已安装的包</li></ul><blockquote><p>全局换源</p></blockquote><div class="language-cmd line-numbers-mode" data-highlighter="prismjs" data-ext="cmd"><pre><code><span class="line"># 设置清华源</span>
<span class="line">pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple</span>
<span class="line"># 查看源</span>
<span class="line">pip config get global.index-url </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>阿里云源: http://mirrors.aliyun.com/pypi/simple</li><li>Pypi默认源: https://pypi.org/</li></ul><h2 id="jupyter-notebook工具" tabindex="-1"><a class="header-anchor" href="#jupyter-notebook工具"><span>Jupyter notebook工具</span></a></h2><p>Jupyter Notebook 是一个开源的交互式 Web 工具, 它支持 <strong>代码执行、可视化、Markdown 文档和数学公式</strong>，适用于 Python等多种语言</p><ul><li>可在工具中执行python代码</li></ul><blockquote><p>安装并使用</p></blockquote><div class="language-cmd line-numbers-mode" data-highlighter="prismjs" data-ext="cmd"><pre><code><span class="line">pip install notebook</span>
<span class="line"></span>
<span class="line"># 安装完成, 运行:</span>
<span class="line">jupyter notebook  # 浏览器会自动打开 http://localhost:8888（默认端口 8888）</span>
<span class="line">jupyter notebook --port 9999 # 指定端口执行</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意: 如果安装不成功,先将pip升级<code>python -m pip install --upgrade pip</code> 再重新安装一下notebook</p><h3 id="mac安装" tabindex="-1"><a class="header-anchor" href="#mac安装"><span>mac安装</span></a></h3><ul><li>mac安装notebook命令 <ul><li>pip3 install --user jupyter</li></ul></li><li>mac启动notebook命令 <ul><li>python3 -m IPython notebook</li></ul></li></ul><h3 id="初步使用" tabindex="-1"><a class="header-anchor" href="#初步使用"><span>初步使用</span></a></h3><blockquote><p>注意: 尽可能的放置在其他盘, 比如在D盘创建一个文件夹,在其中打开cmd,通过指令执行jupyter notebook, 后续创建的内容会再该文件中</p></blockquote><p>在浏览器地址栏输入: http://localhost:8888 打开笔记工具</p><p><img src="https://api2.mubu.com/v3/document_image/7637318_9e39641f-9d48-4442-c9c6-8a6b0d0f17d4.png" alt=""></p><h2 id="爬虫的基础流程" tabindex="-1"><a class="header-anchor" href="#爬虫的基础流程"><span>爬虫的基础流程</span></a></h2><h3 id="流程" tabindex="-1"><a class="header-anchor" href="#流程"><span>流程</span></a></h3><ol><li>发起请求 <ul><li>通过HTTP库向目标站点发起请求，即发送一个Request，请求可以包含额外的headers等信息，等待服务器响应</li></ul></li><li>获取响应内容 <ul><li>如果服务器能正常响应，会得到一个Response，Response的内容便是所要获取的页面内容，类型可能有HTML，JSON字符串，二进制数据（如图片视频）等类型</li></ul></li><li>解析内容 <ul><li>得到的内容可能是HTML，可以用正则表达式、网页解析库进行解析。可能是JSON，可以直接转为JSON对象解析，可能是二进制数据，可以做保存或者进一步的处理</li></ul></li><li>保存数据 <ul><li>保存形式多样，可以保存为文本，也可以保存至数据库，或者保存特定格式的文件。</li></ul></li></ol><h3 id="request和response" tabindex="-1"><a class="header-anchor" href="#request和response"><span>Request和Response</span></a></h3><p>Request: 浏览器发起请求携带数据消息到网址所在的服务器，这个过程叫做HTTP Request</p><p>Response: 服务器返回携带数据给浏览器。这个过程叫做HTTP Response。</p><h4 id="request" tabindex="-1"><a class="header-anchor" href="#request"><span>Request</span></a></h4><ul><li>请求方式: 主要有GET、POST两种类型，另外还有HEAD、PUT、DELETE、OPTIONS等</li><li>请求URL: URL全称统一资源定位符，如一个网页文档、一张图片、一个视频等都可以用URL唯一来确定</li><li>请求头: 包含请求时的头部信息，如User-Agent、Host、Cookies等信息</li><li>请求体: 请求时额外携带的数据如表单提交时的表单数据</li></ul><h4 id="response" tabindex="-1"><a class="header-anchor" href="#response"><span>Response</span></a></h4><ul><li>响应状态: 有多种响应状态，如200代表成功、301跳转、404找不到页面、502服务器错误</li><li>响应头: 如内容类型、内容长度、服务器信息、设置Cookie等等</li><li>响应体: 最主要的部分，包含了请求资源的内容，如网页HTML、图片二进制数据等。</li></ul><h3 id="能抓取的数据" tabindex="-1"><a class="header-anchor" href="#能抓取的数据"><span>能抓取的数据</span></a></h3><ul><li>HTML文档、Json格式文本等</li><li>图片</li><li>视频，音频</li><li>其他（只要能请求到的 就意味着都能获取到）</li></ul><h3 id="解析数据" tabindex="-1"><a class="header-anchor" href="#解析数据"><span>解析数据</span></a></h3><ol><li>直接处理</li><li>JSON数据解析</li><li>正则表达式</li><li>BeautifulSoup</li><li>PyQuery</li><li>XPath</li></ol><h3 id="保存数据" tabindex="-1"><a class="header-anchor" href="#保存数据"><span>保存数据</span></a></h3><ul><li>文本: 纯文本、Json、Xml等</li><li>数据库: 如MySQL、Oracle、SQL Server等具有结构化表结构形式存储等等</li><li>二进制文件: 如图片、视频、音频等等直接保存成特定格式即可。</li></ul>`,59)])])}const p=e(a,[["render",t]]),d=JSON.parse('{"path":"/spider/01-%E7%88%AC%E8%99%AB%E7%AE%80%E4%BB%8B.html","title":"","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"什么爬虫","slug":"什么爬虫","link":"#什么爬虫","children":[{"level":3,"title":"通用网络爬虫","slug":"通用网络爬虫","link":"#通用网络爬虫","children":[]},{"level":3,"title":"聚焦网络爬虫","slug":"聚焦网络爬虫","link":"#聚焦网络爬虫","children":[]},{"level":3,"title":"增量式网络爬虫","slug":"增量式网络爬虫","link":"#增量式网络爬虫","children":[]},{"level":3,"title":"robots协议","slug":"robots协议","link":"#robots协议","children":[]},{"level":3,"title":"法律和道德问题","slug":"法律和道德问题","link":"#法律和道德问题","children":[]}]},{"level":2,"title":"pip使用","slug":"pip使用","link":"#pip使用","children":[]},{"level":2,"title":"Jupyter notebook工具","slug":"jupyter-notebook工具","link":"#jupyter-notebook工具","children":[{"level":3,"title":"mac安装","slug":"mac安装","link":"#mac安装","children":[]},{"level":3,"title":"初步使用","slug":"初步使用","link":"#初步使用","children":[]}]},{"level":2,"title":"爬虫的基础流程","slug":"爬虫的基础流程","link":"#爬虫的基础流程","children":[{"level":3,"title":"流程","slug":"流程","link":"#流程","children":[]},{"level":3,"title":"Request和Response","slug":"request和response","link":"#request和response","children":[]},{"level":3,"title":"能抓取的数据","slug":"能抓取的数据","link":"#能抓取的数据","children":[]},{"level":3,"title":"解析数据","slug":"解析数据","link":"#解析数据","children":[]},{"level":3,"title":"保存数据","slug":"保存数据","link":"#保存数据","children":[]}]}],"git":{},"filePathRelative":"spider/01-爬虫简介.md"}');export{p as comp,d as data};
